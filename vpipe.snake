from collections import namedtuple

import configparser
import csv
import os
import sys

config = configparser.ConfigParser()
config.read('snake.config')
samples = config['input']['samples']
FASTQ_SUFFIX = config['input']['fastq_suffix']
LEAVE_MSA_TEMP = config.getboolean('align', 'leave_msa_temp')

# generate list of alignments to generate
all_files = []
consensus_skeletons = []
trimmed_files = []
vicuna_refs = []

# OUTPUT FILES
with open(samples, newline='') as csvfile:
    spamreader = csv.reader(csvfile, delimiter='\t')
    for row in spamreader:
        all_files.append(
            "patients/{patient}/{date}/alignments/HXB2_aln.bam".format(patient=row[0], date=row[1]))
        all_files.append(
            "patients/{patient}/{date}/QA_alignments/coverage_ambig.tsv".format(patient=row[0], date=row[1]))
        all_files.append(
            "patients/{patient}/{date}/QA_alignments/coverage_majority.tsv".format(patient=row[0], date=row[1]))

        vicuna_refs.append(
            "patients/{patient}/{date}/references/vicuna_consensus.fasta".format(patient=row[0], date=row[1]))
        consensus_skeletons.append(
            "patients/{patient}/{date}/references/ref_".format(patient=row[0], date=row[1]))

        trimmed_files.append(
            "patients/{patient}/{date}/preprocessed_data/R1.fastq.gz".format(patient=row[0], date=row[1]))
        trimmed_files.append(
            "patients/{patient}/{date}/preprocessed_data/R2.fastq.gz".format(patient=row[0], date=row[1]))

# DUMMY RULES
rule all:
    input:
        all_files

rule alltrimmed:
    input:
        trimmed_files


# 1. extract
rule gunzip:
    input:
        "{file}.fastq.gz"
    output:
        temp("{file}.fastq")
    params:
        lsfoutfile = "/dev/null",
        lsferrfile = "/dev/null",
        scratch = '10000',
        mem = '30000',
        time = '60'
    threads:
        1
    shell:
        """
        gunzip -c {input} > {output}
        """


def construct_input_fastq(wildcards):
    inferred_values = glob_wildcards(
        wildcards.dataset + "/raw_data/{file}R" + wildcards.pair + FASTQ_SUFFIX + ".fastq.gz")
    list_output = []

    for i in inferred_values.file:
        list_output.append(wildcards.dataset + "/raw_data/" +
                           i + "R" + wildcards.pair + FASTQ_SUFFIX + ".fastq")

    return list_output


rule extract:
    input:
        construct_input_fastq
    output:
        temp("{dataset}/extracted_data/R{pair}.fastq")
    params:
        lsfoutfile = "{dataset}/extracted_data/extract.lsfout.log",
        lsferrfile = "{dataset}/extracted_data/extract.lsferr.log",
        scratch = '2000',
        mem = '10000',
        time = '20'
    benchmark:
        "{dataset}/extracted_data/extract.benchmark"
    threads:
        1
    shell:
        """
        cat {input} | paste - - - - | sort -k1,1 -t " " | tr "\t" "\n" > {output}
        """

rule extractclean:
    shell:
        """
        rm -rf patients/*/*/extracted_data
        """


# 2. clipping
rule trimming:
    input:
        R1 = "{dataset}/extracted_data/R1.fastq",
        R2 = "{dataset}/extracted_data/R2.fastq"
    output:
        R1gz = "{dataset}/preprocessed_data/R1.fastq.gz",
        R2gz = "{dataset}/preprocessed_data/R2.fastq.gz"
    params:
        lsfoutfile = "{dataset}/preprocessed_data/prinseq.lsfout.log",
        lsferrfile = "{dataset}/preprocessed_data/prinseq.lsferr.log",
        scratch = '2000',
        mem = '2000',
        time = '235',
        PRINSEQ = "/cluster/work/bewi/modules/PRINSEQ/current/prinseq-lite",
    benchmark:
        "{dataset}/preprocessed_data/prinseq.benchmark"
    threads:
        1
    shell:
        """
        if [[ -f {wildcards.dataset}/raw_data/length_cutoff ]]; then
                CUTOFF=$(cat {wildcards.dataset}/raw_data/length_cutoff)
        else
                CUTOFF=200
        fi

        echo "The length cutoff is: ${{CUTOFF}}"

        {params.PRINSEQ} -fastq {input.R1} -fastq2 {input.R2} -out_format 3 -out_good {wildcards.dataset}/preprocessed_data/R -out_bad null -ns_max_n 4 -min_qual_mean 30 -trim_qual_left 30 -trim_qual_right 30 -trim_qual_window 10 -min_len ${{CUTOFF}}

        mv {wildcards.dataset}/preprocessed_data/R{{_,}}1.fastq
        mv {wildcards.dataset}/preprocessed_data/R{{_,}}2.fastq
        rm -f {wildcards.dataset}/preprocessed_data/R_?_singletons.fastq

        gzip {wildcards.dataset}/preprocessed_data/R1.fastq
        gzip {wildcards.dataset}/preprocessed_data/R2.fastq
        """

rule trimmingclean:
    shell:
        """
        rm -rf patients/*/*/preprocessed_data
        """


# 3. initial consensus sequence
rule vicuna_initial:
    input:
        global_ref = "references/HXB2.fasta",
        R1 = "patients/{sample}/preprocessed_data/R1.fastq",
        R2 = "patients/{sample}/preprocessed_data/R2.fastq"
    output:
        "patients/{sample}/references/vicuna_consensus.fasta"
    params:
        lsfoutfile = "patients/{sample}/initial_consensus/vicuna.lsfout.log",
        lsferrfile = "patients/{sample}/initial_consensus/vicuna.lsferr.log",
        scratch = '1000',
        mem = '1000',
        time = '600',
        VICUNA = "/cluster/work/bewi/modules/VICUNA/current/vicuna-omp.static.linux64",
        BWA = "/cluster/work/bewi/modules/bwa/current/bin/bwa",
        WORK_DIR = "patients/{sample}/initial_consensus"
    benchmark:
        'patients/{sample}/initial_consensus/vicuna_consensus.benchmark'
    threads:
        6
    shell:
        """
        CONSENSUS_NAME={wildcards.sample}
        CONSENSUS_NAME="${{CONSENSUS_NAME//\//-}}"
        source functions.sh

        # 1. copy initial reference for bwa
        rm -rf {params.WORK_DIR}/
        mkdir -p {params.WORK_DIR}/
        cp {input.global_ref} {params.WORK_DIR}/consensus.fasta
        cd {params.WORK_DIR}

        # 2. create bwa index
        {params.BWA} index consensus.fasta

        # 3. create initial alignment
        {params.BWA} mem -t {threads} consensus.fasta ../preprocessed_data/R{{1,2}}.fastq > first_aln.sam
        rm consensus.fasta.*

        # 4. remove unmapped reads
        samtools view -b -F 4 first_aln.sam > mapped.bam
        rm first_aln.sam

        # 5. extract reads
        mkdir -p cleaned
        SamToFastq I=mapped.bam FASTQ=cleaned/R1.fastq SECOND_END_FASTQ=cleaned/R2.fastq VALIDATION_STRINGENCY=SILENT
        rm mapped.bam

        # 6. create config file
        cat > vicuna_config.txt <<- _EOF_
                minMSize	9
                maxOverhangSize	2
                Divergence	8
                max_read_overhang	2
                max_contig_overhang	10
                pFqDir	cleaned/
                batchSize	100000
                LibSizeLowerBound	100
                LibSizeUpperBound	800
                min_output_contig_len	1000
                outputDIR	./
        _EOF_

        # 7. VICUNA
        OMP_NUM_THREADS={threads} {params.VICUNA} vicuna_config.txt
        rm vicuna_config.txt
        rm -r cleaned/

        # 8. fix broken header
        sed -e 's:>dg-\([[:digit:]]\+\)\s.*:>dg-\1:g' contig.fasta > contig_clean.fasta

        # 9. InDelFixer + ConsensusFixer to polish up consensus
        for i in {{1..3}}
        do
                mv consensus.fasta old_consensus.fasta
                InDelFixer -i contig_clean.fasta -g old_consensus.fasta
                sam2bam reads.sam
                ConsensusFixer -i reads.bam -r old_consensus.fasta -mcc 1 -mic 1 -d -pluralityN 0.01
        done

        sed -i -e "s/>.*/>${{CONSENSUS_NAME}}/" consensus.fasta
        echo "" >> consensus.fasta

        # 10. finally, move into place
        mkdir -p ../references
        mv {{,../references/vicuna_}}consensus.fasta
        """

rule vicuna_msa:
    input:
        vicuna_refs
    output:
        "references/initial_aln_gap_removed.fasta"
    params:
        lsfoutfile = "references/MAFFT_initial_aln.lsfout.log",
        lsferrfile = "references/MAFFT_initial_aln.lsferr.log",
        scratch = '1250',
        mem = '10000',
        time = '235',
        MAFFT = "/cluster/work/bewi/modules/mafft/current/bin/mafft --nuc --preservecase --maxiterate 1000 --localpair",
        REMOVE_GAPS = "/cluster/work/bewi/modules/SmallGenomeUtilities/current/bin/remove_gaps_msa"
    benchmark:
        "references/MAFFT_initial_aln.benchmark"
    threads:
        24
    shell:
        """
        cat {input} > initial_ALL.fasta
        {params.MAFFT} --thread {threads} initial_ALL.fasta > references/initial_aln.fasta
        rm initial_ALL.fasta

        {params.REMOVE_GAPS} references/initial_aln.fasta -o {output} -p 0.5
        """

localrules: create_vicuna_initial
rule create_vicuna_initial:
    input:
        "references/initial_aln_gap_removed.fasta"
    output:
        "patients/{sample}/references/initial_consensus.fasta"
    params:
        EXTRACT_SEQ = "/cluster/work/bewi/modules/SmallGenomeUtilities/current/bin/extract_seq"
    shell:
        """
        CONSENSUS_NAME={wildcards.sample}
        CONSENSUS_NAME="${{CONSENSUS_NAME//\//-}}"

        mkdir -p patients/{wildcards.sample}/references/
        {params.EXTRACT_SEQ} {input} -o {output} -s "${{CONSENSUS_NAME}}"
        """

localrules: create_simple_initial
rule create_simple_initial:
    input:
        "references/cohort_consensus.fasta"
    output:
        "patients/{sample}/references/initial_consensus.fasta"
    shell:
        """
        CONSENSUS_NAME={wildcards.sample}
        CONSENSUS_NAME="${{CONSENSUS_NAME//\//-}}"

        mkdir -p patients/{wildcards.sample}/references/
        cp {input} {output}
        sed -i -e "s/>.*/>${{CONSENSUS_NAME}}/" {output}
        """

localrules: create_denovo_initial
rule create_denovo_initial:
    input:
        "patients/{sample}/references/denovo_consensus.fasta"
    output:
        "patients/{sample}/references/initial_consensus.fasta"
    shell:
        """
        CONSENSUS_NAME={wildcards.sample}
        CONSENSUS_NAME="${{CONSENSUS_NAME//\//-}}"

        mkdir -p patients/{wildcards.sample}/references/
        cp {input} {output}
        sed -i -e "s/>.*/>${{CONSENSUS_NAME}}/" {output}
        """

rule vicunaclean:
    shell:
        """
        rm -rf patients/*/*/initial_consensus
        rm -rf patients/*/*/references/vicuna_consensus.fasta
        rm -rf patients/*/*/references/initial_consensus.fasta
        rm -rf references/initial_aln.fasta
        rm -rf references/initial_aln_gap_removed.fasta
        rm -rf references/MAFFT_initial_aln.*
        """

# change this to switch between VICUNA and creating a simple (HXB2)
# initial reference
ruleorder: create_denovo_initial > create_simple_initial > create_vicuna_initial
# ruleorder: create_vicuna_initial > create_simple_initial


# 4. aligning
# rule align:
#	input:
#		initial_ref = "patients/{sample}/references/initial_consensus.fasta",
#		R1 = "patients/{sample}/preprocessed_data/R1.fastq",
#		R2 = "patients/{sample}/preprocessed_data/R2.fastq"
#	output:
#		good_aln =   temp("patients/{sample}/alignments/full_aln.sam"),
#		reject_aln = temp("patients/{sample}/alignments/rejects.sam"),
#		REF_ambig =       "patients/{sample}/references/ref_ambig.fasta",
#		REF_majority =    "patients/{sample}/references/ref_majority.fasta"
#	params:
#		lsfoutfile = "patients/{sample}/alignments/ngshmmalign.lsfout.log",
#		lsferrfile = "patients/{sample}/alignments/ngshmmalign.lsferr.log",
#		scratch = '1250',
#		mem = '1250',
#		time = '1435',
#		NGSHMMALIGN = "/cluster/work/bewi/modules/ngshmmalign/current/bin/ngshmmalign",
#		LEAVE_TEMP = '-l' if LEAVE_MSA_TEMP else '',
#		MAFFT = "/cluster/work/bewi/modules/mafft/current/bin/mafft"
#	benchmark:
#		"patients/{sample}/alignments/ngshmmalign.benchmark"
#	threads:
#		24
#	shell:
#		"""
#		CONSENSUS_NAME={wildcards.sample}
#		CONSENSUS_NAME="${{CONSENSUS_NAME//\//-}}"
#
#		# 1. clean previous run
#		rm -rf   patients/{wildcards.sample}/alignments
#		rm -f    patients/{wildcards.sample}/references/ref_ambig.fasta
#		rm -f    patients/{wildcards.sample}/references/ref_majority.fasta
#		mkdir -p patients/{wildcards.sample}/alignments
#		mkdir -p patients/{wildcards.sample}/references
#
#		# 2. perform alignment # -l = leave temps
#		MAFFT_BIN={params.MAFFT} {params.NGSHMMALIGN} -v -R {input.initial_ref} -o {output.good_aln} -w {output.reject_aln} -t {threads} -N "${{CONSENSUS_NAME}}" {params.LEAVE_TEMP} {input.R1} {input.R2}
#
#		# 3. move references into place
#		mv patients/{wildcards.sample}/{{alignments,references}}/ref_ambig.fasta
#		mv patients/{wildcards.sample}/{{alignments,references}}/ref_majority.fasta
#		"""

rule convert_sam_to_bam:
    input:
        "{file}.sam"
    output:
        BAM = "{file}.bam",
        BAI = "{file}.bam.bai"
    params:
        lsfoutfile = "{file}_sam2bam.lsfout.log",
        lsferrfile = "{file}_sam2bam.lsferr.log",
        scratch = '1250',
        mem = '5000',
        time = '30'
    benchmark:
        "{file}_sam2bam.benchmark"
    threads:
        1
    shell:
        """
        # convert sam -> bam
        source functions.sh
        sam2bam {input}
        """

# 4a. align against 5VM as a QA check
rule bwa_align:
    input:
        patient_ref = "patients/{sample}/references/ref_{kind}.fasta",
        virusmix_ref = "references/5-Virus-Mix.fasta",
        R1 = "patients/{sample}/preprocessed_data/R1.fastq",
        R2 = "patients/{sample}/preprocessed_data/R2.fastq",
    output:
        SAM = temp("patients/{sample}/QA_alignments/bwa_aln_{kind}.sam"),
        MSA = "patients/{sample}/QA_alignments/bwa_refs_msa_{kind}.fasta",
    params:
        lsfoutfile = "patients/{sample}/QA_alignments/bwa_{kind}.lsfout.log",
        lsferrfile = "patients/{sample}/QA_alignments/bwa_{kind}.lsferr.log",
        scratch = '1250',
        mem = '1250',
        time = '235',
        BWA = "/cluster/work/bewi/modules/bwa/current/bin/bwa",
        MAFFT = "/cluster/work/bewi/modules/mafft/current/bin/mafft --nuc --preservecase --maxiterate 1000 --localpair",
    benchmark:
        "patients/{sample}/QA_alignments/bwa_{kind}.benchmark"
    threads:
        6
    shell:
        """
        # 1. cleanup old run
        rm -f {output.SAM} {output.MSA}

        # 2. concatenate references
        mkdir -p patients/{wildcards.sample}/QA_alignments
        cat {input.patient_ref} {input.virusmix_ref} > patients/{wildcards.sample}/QA_alignments/bwa_refs_{wildcards.kind}.fasta

        # 3. indexing
        {params.BWA} index patients/{wildcards.sample}/QA_alignments/bwa_refs_{wildcards.kind}.fasta

        # 4. align
        {params.BWA} mem -t {threads} patients/{wildcards.sample}/QA_alignments/bwa_refs_{wildcards.kind}.fasta {input.R1} {input.R2} > {output.SAM}

        # 5. MSA
        {params.MAFFT} --thread {threads} patients/{wildcards.sample}/QA_alignments/bwa_refs_{wildcards.kind}.fasta > {output.MSA}

        # 6. cleanup BWA indices
        rm -f patients/{wildcards.sample}/QA_alignments/bwa_refs_{wildcards.kind}.fasta.*
        """

# 4b. Call coverage statistics
rule coverage_QA:
    input:
        BAM = "patients/{sample}/QA_alignments/bwa_aln_{kind}.bam",
        MSA = "patients/{sample}/QA_alignments/bwa_refs_msa_{kind}.fasta",
    output:
        "patients/{sample}/QA_alignments/coverage_{kind}.tsv",
    params:
        lsfoutfile = "patients/{sample}/QA_alignments/coverage_QA_{kind}.lsfout.log",
        lsferrfile = "patients/{sample}/QA_alignments/coverage_QA_{kind}.lsferr.log",
        scratch = '1250',
        mem = '1250',
        time = '235',
        COV_STATS = "/cluster/work/bewi/modules/SmallGenomeUtilities/current/bin/coverage_stats",
    benchmark:
        "patients/{sample}/QA_alignments/coverage_QA_{kind}.benchmark"
    threads:
        1
    shell:
        """
        CONSENSUS_NAME={wildcards.sample}
        CONSENSUS_NAME="${{CONSENSUS_NAME//\//-}}"

        # 1. clean previous run
        rm -f {output}
        mkdir -p patients/{wildcards.sample}/QA_alignments

        # 2. collect coverage stats
        {params.COV_STATS} -t HXB2:6614-6812,7109-7217,7376-7478,7601-7634 -i {input.BAM} -o {output} -m {input.MSA} --select "${{CONSENSUS_NAME}}"
        """


# 5. construct MSA from all patient files
def construct_msa_input_files(wildcards):
    output_list = ["{}{}.fasta".format(s, wildcards.kind)
                   for s in consensus_skeletons]
    output_list.append("references/HXB2.fasta")

    return output_list


rule msa:
    input:
        construct_msa_input_files
    output:
        "references/ALL_aln_{kind}.fasta"
    params:
        lsfoutfile = "references/MAFFT_{kind}_cohort.lsfout.log",
        lsferrfile = "references/MAFFT_{kind}_cohort.lsferr.log",
        scratch = '1250',
        mem = '10000',
        time = '235',
        MAFFT = "/cluster/work/bewi/modules/mafft/current/bin/mafft --nuc --preservecase --maxiterate 1000 --localpair",
    benchmark:
        "references/MAFFT_{kind}_cohort.benchmark"
    threads:
        24
    shell:
        """
        cat {input} > ALL_{wildcards.kind}.fasta
        {params.MAFFT} --thread {threads} ALL_{wildcards.kind}.fasta > {output}
        rm ALL_{wildcards.kind}.fasta
        """

rule msaclean:
    shell:
        """
        rm -rf references/ALL_aln_*.fasta
        rm -rf references/MAFFT_*_cohort.*
        """


# 6. convert alignments to HXB2 alignment
rule convert_to_hxb2:
    input:
        REF_ambig = "references/ALL_aln_ambig.fasta",
        REF_majority = "references/ALL_aln_majority.fasta",
        BAM = "{dataset}/alignments/full_aln.bam",
        REJECTS_BAM = "{dataset}/alignments/rejects.bam",
    output:
        "{dataset}/alignments/HXB2_aln.bam"
    params:
        lsfoutfile = "{dataset}/alignments/convert_to_HXB2.lsfout.log",
        lsferrfile = "{dataset}/alignments/convert_to_HXB2.lsferr.log",
        scratch = '1250',
        mem = '8000',
        time = '235',
        CONVERT_REFERENCE = "/cluster/work/bewi/modules/SmallGenomeUtilities/current/bin/convert_reference"
    benchmark:
        "{dataset}/alignments/convert_to_HXB2.benchmark"
    threads:
        1
    shadow:
        "shallow"
    shell:
        """
        {params.CONVERT_REFERENCE} -t HXB2 -m {input.REF_ambig} -i {input.BAM} -o {output}
        """


rule alignclean:
    shell:
        """
        rm -rf patients/*/*/alignments
        rm -rf patients/*/*/QA_alignments
        rm -rf patients/*/*/references/ref_ambig.fasta
        rm -rf patients/*/*/references/ref_majority.fasta
        """
